{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a05e0d2",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP)\n",
    "\n",
    "Multilayer perceptron (MLP) is a supplement of feed forward neural network. It consists of three types of layersâ€”the input layer, hidden layer, and output layer. The input layer receives the input signal to be processed. The required task such as prediction and classification is performed by the output layer. An arbitrary number of hidden layers that are placed in between the input and output layer are the true computational engine of the MLP. Similar to a feed forward network in a MLP the data flows in the forward direction from input to output layer. The neurons in the MLP are trained with the back propagation learning algorithm. MLPs are designed to approximate any continuous function and can solve problems which are not linearly separable. The major use cases of MLP are pattern classification, recognition, prediction and approximation.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Ryan-Heartfield/publication/321341597/figure/fig5/AS:667675554480148@1536197665532/MLP-deep-learning-architecture.ppm\" width=\"550\" height=\"380\"/>\n",
    "\n",
    "### Layers and activation function\n",
    "\n",
    "The MLP consists of three or more layers (an input and an output layer with one or more hidden layers) of nonlinearly-activating nodes. Since MLPs are fully connected, each node in one layer connects with a certain weight ${\\displaystyle w_{ij}}$ to every node in the following layer. For each layer $l$, it will have two phases. The preactivation phase consists of a weighted linear combination of postactivation values in the previous layer. The postactivation values consists of passing the preactivation value through a chosen activation function elementwise. In MLP, some neurons use a nonlinear activation function. The two historically common activation functions are described by:\n",
    "\n",
    "$$\n",
    "y(\\upsilon_i) = tanh(\\upsilon_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "y(\\upsilon_i) = \\frac{1}{1 + e^{-\\upsilon_i}}\n",
    "$$\n",
    "\n",
    "In recent developments of deep learning the rectifier linear unit (ReLU) is more frequently used as one of the possible ways to overcome the numerical problems related to the sigmoids. The plot above uses the ReLU.\n",
    "\n",
    "### Learning\n",
    "\n",
    "Learning occurs in the perceptron by changing connection weights after each piece of data is processed, based on the amount of error in the output compared to the expected result. This is an example of supervised learning, and is carried out through backpropagation, a generalization of the least mean squares algorithm in the linear perceptron.\n",
    "\n",
    "We can represent the degree of error in an output node ${\\displaystyle j}$ in the ${\\displaystyle n}$th data point (training example) by ${\\displaystyle e_{j}(n)=d_{j}(n)-y_{j}(n)}$, where ${\\displaystyle d}$ is the target value and ${\\displaystyle y}$ is the value produced by the perceptron. The node weights can then be adjusted based on corrections that minimize the error in the entire output, given by ${\\displaystyle {\\mathcal {E}}(n)={\\frac {1}{2}}\\sum _{j}e_{j}^{2}(n)}$.\n",
    "\n",
    "Using gradient descent, the change in each weight is ${\\displaystyle \\Delta w_{ji}(n) = -\\eta {\\frac {\\partial {\\mathcal {E}}(n)}{\\partial v_{j}(n)}}y_{i}(n)}$, where ${\\displaystyle y_{i}}$ is the output of the previous neuron and ${\\displaystyle \\eta }$ is the learning rate, which is selected to ensure that the weights quickly converge to a response, without oscillations.\n",
    "\n",
    "### Mini Batch\n",
    "\n",
    "Mini batch divides the training data records into groups of approximately equal size, then updates the synaptic weights after passing one group; that is, mini-batch training uses information from a group of records. Then the process recycles the data group if necessary. Mini-batch training offers a compromise between batch and online training, and it may be best for \"medium-size\" datasets. The procedure can automatically determine the number of training records per mini-batch, or you can specify an integer greater than 1 and less than or equal to the maximum number of cases to store in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabedf80",
   "metadata": {},
   "source": [
    "# My Implementation on CIFAR10 Small Images Classification Dataset\n",
    "\n",
    "I choose to implement the MLP algorithm using the CIFAR10 Small Images Classification Dataset from keras.datasets. The CIFAR10 Small Images Classification Dataset is a dataset of 50,000 32 $\\times$ 32 color training images and 10,000 test images, labeled over 10 categories. Below are the 10 categories:\n",
    "\n",
    "* Label 0: airplane\n",
    "* Label 1: automobile\n",
    "* Label 2: bird\n",
    "* Label 3: cat\n",
    "* Label 4: deer\n",
    "* Label 5: dog\n",
    "* Label 6: frog\n",
    "* Label 7: horse\n",
    "* Label 8: ship\n",
    "* Label 9: truck\n",
    "\n",
    "For this dataset, We build a multilayered perceptron with a single input layer with 3072 input nodes, 2 hidden layers of arbitrary size, and 10 output nodes. These layers will be denoted $L^0, L^1, L^2,$ and $L^{3}$, respectively. \n",
    "\n",
    "For $l = 1, 2, 3$, layer $l$ will have two phases:\n",
    "\n",
    "* The preactivation phase $z^l = W^la^{l-1} + b^l,$ \n",
    "* The postactivation phase $a^l = \\sigma(z^l).$ \n",
    "\n",
    "For notational convience, we let $a^0 = x$, where $x$ is the current input data into our network. For our activation function, we will use the sigmoid function.\n",
    "\n",
    "$$\n",
    "\\sigma(s) = \\frac{1}{1+e^{-s}}.\n",
    "$$\n",
    "\n",
    "For our cost function, we will use the Mean Sqaure Error (MSE) cost.\n",
    "$$\n",
    "C = C(W, b) = \\frac{1}{2}\\sum_{i=1}^n(a^i - y^i)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e0561",
   "metadata": {},
   "source": [
    "# Coding Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a61695",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b213cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras # To load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c8cbe",
   "metadata": {},
   "source": [
    "Load the CIFAR10 small images classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c044cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02ebc18",
   "metadata": {},
   "source": [
    "#### Check the shape of X in the training set\n",
    "\n",
    "This is a dataset of 50,000 32 $\\times$ 32 color training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf86b22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4f62e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8ee22",
   "metadata": {},
   "source": [
    "#### Check the shape of y in the training set\n",
    "\n",
    "It has a shape of (50,000, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd96cd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed99e0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c9ad35",
   "metadata": {},
   "source": [
    "### Visualization of the training set\n",
    "\n",
    "Let's take a look at the first image in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f782a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fce0a141310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_X[0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770f129",
   "metadata": {},
   "source": [
    "Now, check the maximum of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e834fedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892969e",
   "metadata": {},
   "source": [
    "The maximum is 255, so we scale the training set and the test set by dividing them by 255. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bda3fab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X/255\n",
    "test_X = test_X/255\n",
    "test_X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84140d43",
   "metadata": {},
   "source": [
    "Change test_X[0]  to a list by using \"flatten\", so now it has a length of 32 $\\times$ 32 $\\times$ 3 = 3072. Then reshape it to (3072, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "791b145a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1135805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0].flatten().reshape(3072, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a31a9a",
   "metadata": {},
   "source": [
    "For the training set, we write for loops to temporarily store flattened matrices into X and temporarily store one-hot encoded label vectors into Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd788a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X will temp store flattened matrices\n",
    "X = []\n",
    "for x in train_X:\n",
    "  X.append(x.flatten().reshape(3072, 1))\n",
    "\n",
    "# Y will temp store one-hot encoded label vectors\n",
    "Y = []\n",
    "for y in train_y:\n",
    "  temp_vec = np.zeros((10, 1))\n",
    "  temp_vec[y][0] = 1.0\n",
    "  Y.append(temp_vec)\n",
    "\n",
    "# Our data will be stored as a list of tuples. \n",
    "train_data = [p for p in zip(X, Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d269a",
   "metadata": {},
   "source": [
    "Let $p$ to be the first training data combining X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f5d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "p = train_data[0]\n",
    "print(p[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b086c0",
   "metadata": {},
   "source": [
    "Perform the similar for loops on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ea8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for x in test_X:\n",
    "  X.append(x.flatten().reshape(3072, 1))\n",
    "\n",
    "Y = []\n",
    "for y in test_y:\n",
    "  temp_vec = np.zeros((10, 1))\n",
    "  temp_vec[y][0] = 1.0\n",
    "  Y.append(temp_vec)\n",
    "\n",
    "test_data = [p for p in zip(X, Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4581aa",
   "metadata": {},
   "source": [
    "### Sigmoid\n",
    "\n",
    "Now define a sigmoid function: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$.\n",
    "\n",
    "Define a function for the first derivative of the sigmoid called \"sigmoid_prime\".\n",
    "\n",
    "Also define a loss function MSE: $C = C(W, b) = \\frac{1}{2}\\sum_{i=1}^n(a^i - y^i)^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b76b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "  return sigmoid(z)*(1.0 - sigmoid(z))\n",
    "\n",
    "def mse(a, y):\n",
    "  return .5*sum((a[i]-y[i])**2 for i in range(10))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db85d68e",
   "metadata": {},
   "source": [
    "Define a function to initialze weights and bias. The parameters are the number of input data in the first layer (3072), number of nodes in the hidden layers (60), and the number of nodes for the last layer (10) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63391bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(layers = [3072, 60, 60, 10]):\n",
    "  W = [[0.0]] # W = [[0,0],W1,W2,W3], placeholder\n",
    "  B = [[0.0]]\n",
    "  for i in range(1, len(layers)):\n",
    "    w_temp = np.random.randn(layers[i], layers[i-1])*np.sqrt(2/layers[i-1])\n",
    "    b_temp = np.random.randn(layers[i], 1)*np.sqrt(2/layers[i-1])\n",
    "\n",
    "    W.append(w_temp)\n",
    "    B.append(b_temp)\n",
    "  return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80cdc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, B = initialize_weights() #store W and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf128067",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f96ae6",
   "metadata": {},
   "source": [
    "### First layer:\n",
    "\n",
    "The general steps here is:\n",
    "1. let $a^0 = x$.\n",
    "2. for $i = 1$ to $L$, $z^l = W^l a^{l-1} + b^l$.\n",
    "3. $a^l = \\sigma(z^l)$.\n",
    "4. Finish with $a^L$. We will then get the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02537238",
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = x\n",
    "z1 = (W[1] @ a0) + B[1]\n",
    "a1 = sigmoid(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a854bbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca4654",
   "metadata": {},
   "source": [
    "### Second layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "872e485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n"
     ]
    }
   ],
   "source": [
    "z2 = (W[2] @ a1) + B[2]\n",
    "a2 = sigmoid(z2)\n",
    "print(a2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c69ea7",
   "metadata": {},
   "source": [
    "### Third layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b34c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "z3 = (W[3] @ a2) + B[3]\n",
    "a3 = sigmoid(z3)\n",
    "print(a3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e9175",
   "metadata": {},
   "source": [
    "Now, combine everything and feed forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1eee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, B = initialize_weights(layers = [3072, 60, 60, 10])\n",
    "x, y = train_data[0]\n",
    "Z = [[0.0]]\n",
    "A = [x]\n",
    "L = len(B)\n",
    "for i in range(1, L):\n",
    "  z = (W[i] @ A[i - 1]) + B[i]\n",
    "  a = sigmoid(z)\n",
    "\n",
    "  Z.append(z)\n",
    "  A.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926d43d",
   "metadata": {},
   "source": [
    "Here, let's check the shape of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cd82776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c0d98",
   "metadata": {},
   "source": [
    "### Delta values\n",
    "\n",
    "Now, create a dictionary to store \"deltas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cedcb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = dict()\n",
    "delta_last = (A[-1] - y)*sigmoid_prime(Z[-1])\n",
    "deltas[L - 1] = delta_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ce67d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10564568],\n",
       "       [0.08269028],\n",
       "       [0.06008889],\n",
       "       [0.11424824],\n",
       "       [0.1384495 ],\n",
       "       [0.03540554],\n",
       "       [0.05571181],\n",
       "       [0.14444934],\n",
       "       [0.10420363],\n",
       "       [0.11660978]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas[L - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1be258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(L - 2, 0, -1):\n",
    "  deltas[l] = (W[l+1].T @ deltas[l+1])*sigmoid_prime(Z[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c46bfb",
   "metadata": {},
   "source": [
    "Check the shape of the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16ee34ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5b5334",
   "metadata": {},
   "source": [
    "Check the shape of the second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1bce9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc50db",
   "metadata": {},
   "source": [
    "Check the shape of the third layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb630781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas[3].shape #bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f4a8d",
   "metadata": {},
   "source": [
    "Set the learning rate $\\alpha$ to 0.04 and perform gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e8770f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.04\n",
    "for i in range(1, 4):\n",
    "  W[i] = W[i] - alpha*deltas[i]@A[i - 1].T\n",
    "  B[i] = B[i] - alpha*deltas[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e563f731",
   "metadata": {},
   "source": [
    "Now combine everthing and feed forward. Do the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfafca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(W, B, p, predict_vector = False):\n",
    "  Z =[[0.0]]\n",
    "  A = [p[0]]\n",
    "  L = len(W)\n",
    "  for i in range(1, L):\n",
    "    z = (W[i] @ A[i - 1]) + B[i]\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    Z.append(z)\n",
    "    A.append(a)\n",
    "\n",
    "  if predict_vector == True:\n",
    "    return A[-1]\n",
    "  else:\n",
    "    return Z, A\n",
    "\n",
    "def deltas_dict(W, B, p):\n",
    "  Z, A = forward_pass(W, B, p)\n",
    "  L = len(W)\n",
    "  deltas = dict()\n",
    "  deltas[L-1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
    "  for l in range(L - 2, 0, -1):\n",
    "    deltas[l] = (W[l+1].T @ deltas[l + 1]) * sigmoid_prime(Z[l])\n",
    "\n",
    "  return A, deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0db95",
   "metadata": {},
   "source": [
    "Define a function for MSE with feed forward prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e1cf3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(W, B, data):\n",
    "  c = 0.0\n",
    "  for p in data:\n",
    "    a = forward_pass(W, B, p, predict_vector = True)\n",
    "    c += mse(a, p[1])\n",
    "  return c/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946ab93",
   "metadata": {},
   "source": [
    "Print the initial cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91fc1725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 1.5940682147095273\n"
     ]
    }
   ],
   "source": [
    "W, B = initialize_weights()\n",
    "print(f\"Initial Cost = {MSE(W, B, train_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae1be4",
   "metadata": {},
   "source": [
    "The initial cost is 1.5940682147095273."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb89fc",
   "metadata": {},
   "source": [
    "See how the predicted value compared with the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "130b55d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value = 9\n",
      "Actual Value = [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0, len(test_X))\n",
    "prediction = np.argmax(forward_pass(W, B, test_data[i], predict_vector = True))\n",
    "print(f\"Predicted Value = {prediction}\")\n",
    "print(f\"Actual Value = {test_y[i]}\")\n",
    "plt.imshow(test_X[i], cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276dd78",
   "metadata": {},
   "source": [
    "The prediction is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ae7e5",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "Now let's formally define a function for gradient descent with a learning rate $\\alpha = 0.04$ and set $epochs = 3$. Recall that epochs is the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1d89c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(W, B, data, alpha = 0.04, epochs = 3):\n",
    "  L = len(W)\n",
    "  print(f\"Initial Cost = {MSE(W, B, data)}\")\n",
    "  for k in range(epochs):\n",
    "    for p in data:\n",
    "      A, deltas = deltas_dict(W, B, p)\n",
    "      for i in range(1, L):\n",
    "        W[i] = W[i] - alpha*deltas[i]@A[i - 1].T\n",
    "        B[i] = B[i] - alpha*deltas[i]\n",
    "    print(f\"{k} Cost = {MSE(W, B, data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fc6931d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 1.5940682147095273\n",
      "0 Cost = 3.519850024784825e-05\n",
      "1 Cost = 1.710284579657265e-05\n",
      "2 Cost = 1.1226896192562181e-05\n"
     ]
    }
   ],
   "source": [
    "stochastic_gradient_descent(W, B, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9310384",
   "metadata": {},
   "source": [
    "We now get three costs. The cost decreases a lot after each training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14035b50",
   "metadata": {},
   "source": [
    "Finally, combine everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c7a6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron():\n",
    "  \n",
    "  def __init__(self, layers = [3072, 60, 60, 10]):\n",
    "    self.layers = layers\n",
    "    self.L = len(self.layers)\n",
    "    self.W =[[0.0]]\n",
    "    self.B = [[0.0]]\n",
    "    for i in range(1, self.L):\n",
    "      w_temp = np.random.randn(self.layers[i], self.layers[i - 1])*np.sqrt(2/self.layers[i - 1])\n",
    "      b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
    "\n",
    "      self.W.append(w_temp)\n",
    "      self.B.append(b_temp)\n",
    "\n",
    "  def reset_weights(self, layers = [3072, 60, 60, 10]):\n",
    "    self.layers = layers\n",
    "    self.L = len(self.layers)\n",
    "    self.W = [[0.0]]\n",
    "    self.B = [[0.0]]\n",
    "    for i in range(1, self.L):\n",
    "      w_temp = np.random.randn(self.layers[i], self.layers[i - 1])*np.sqrt(2/self.layers[i - 1])\n",
    "      b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
    "\n",
    "      self.W.append(w_temp)\n",
    "      self.B.append(b_temp)\n",
    "\n",
    "\n",
    "  def forward_pass(self, p, predict_vector = False):\n",
    "    Z =[[0.0]]\n",
    "    A = [p[0]]\n",
    "    for i in range(1, self.L):\n",
    "      z = (self.W[i] @ A[i - 1]) + self.B[i]\n",
    "      a = sigmoid(z)\n",
    "      Z.append(z)\n",
    "      A.append(a)\n",
    "\n",
    "    if predict_vector == True:\n",
    "      return A[-1]\n",
    "    else:\n",
    "      return Z, A\n",
    "\n",
    "  def MSE(self, data):\n",
    "    c = 0.0\n",
    "    for p in data:\n",
    "      a = self.forward_pass(p, predict_vector=True)\n",
    "      c += mse(a, p[1])\n",
    "    return c/len(data)\n",
    "\n",
    "  def deltas_dict(self, p):\n",
    "    Z, A = self.forward_pass(p)\n",
    "    deltas = dict()\n",
    "    deltas[self.L - 1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
    "    for l in range(self.L - 2, 0, -1):\n",
    "      deltas[l] = (self.W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
    "\n",
    "    return A, deltas\n",
    "\n",
    "  def stochastic_gradient_descent(self, data, alpha = 0.04, epochs = 3):\n",
    "    print(f\"Initial Cost = {self.MSE(data)}\")\n",
    "    for k in range(epochs):\n",
    "      for p in data:\n",
    "        A, deltas = self.deltas_dict(p)\n",
    "        for i in range(1, self.L):\n",
    "          self.W[i] = self.W[i] - alpha*deltas[i]@A[i - 1].T\n",
    "          self.B[i] = self.B[i] - alpha*deltas[i]\n",
    "    print(f\"{k} Cost = {self.MSE(data)}\")\n",
    "\n",
    "  def mini_batch_gradient_descent(self, data, batch_size = 15, alpha = 0.04, epochs = 3):\n",
    "    print(f\"Initial Cost = {self.MSE(data)}\")\n",
    "    data_length = len(data)\n",
    "    for k in range(epochs):\n",
    "      for j in range(0,data_length-batch_size,batch_size):\n",
    "        delta_list = []\n",
    "        A_list = []\n",
    "        for p in data[j:j + batch_size]:\n",
    "          A, deltas = self.deltas_dict(p)\n",
    "          A_list.append(A)\n",
    "\n",
    "          for i in range(1, self.L):\n",
    "            self.W[i] = self.W[i] - (alpha/batch_size)*sum(da[0][i]@da[1][i - 1].T for da in zip(delta_list, A_list))\n",
    "            self.B[i] = self.B[i] - (alpha/batch_size)*sum(deltas[i] for deltas in delta_list)\n",
    "    print(f\"{k} Cost = {self.MSE(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43e9c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MultilayerPerceptron(layers = [3072, 60, 60, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece13e7c",
   "metadata": {},
   "source": [
    "### Costs when using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4f16753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 1.3770877868538627\n",
      "2 Cost = 1.1815340223468933e-05\n"
     ]
    }
   ],
   "source": [
    "net.stochastic_gradient_descent(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746a596",
   "metadata": {},
   "source": [
    "### Cost when using Mini Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5551a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 1.1815340223468933e-05\n",
      "2 Cost = 1.1815340223468933e-05\n"
     ]
    }
   ],
   "source": [
    "net.mini_batch_gradient_descent(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e389890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1767070640785814e-05"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.MSE(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a5ff1",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "S. Abirami, P. Chitra (2020). Multilayer Perceptron. Advances in Computers. https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron\n",
    "\n",
    "Training (Multilayer Perceptron). https://www.ibm.com/docs/en/spss-statistics/24.0.0?topic=perceptron-training-multilayer\n",
    "\n",
    "Multilayer perceptron. Wikipedia. https://en.wikipedia.org/wiki/Multilayer_perceptron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
